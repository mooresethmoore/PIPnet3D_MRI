{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import random\n",
    "import pandas as pd\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    RandRotate,\n",
    "    Affine,\n",
    "    RandGaussianNoise,\n",
    "    RandZoom,\n",
    "    RepeatChannel,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StagingNodes'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yflags=pd.read_csv(\"../duke/ClinicalFlags.csv\",index_col=0)\n",
    "yflags.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Breast_MRI_001', 'Breast_MRI_002', 'Breast_MRI_003', 'Breast_MRI_004',\n",
       "       'Breast_MRI_005', 'Breast_MRI_006', 'Breast_MRI_007', 'Breast_MRI_008',\n",
       "       'Breast_MRI_009', 'Breast_MRI_010',\n",
       "       ...\n",
       "       'Breast_MRI_913', 'Breast_MRI_914', 'Breast_MRI_915', 'Breast_MRI_916',\n",
       "       'Breast_MRI_917', 'Breast_MRI_918', 'Breast_MRI_919', 'Breast_MRI_920',\n",
       "       'Breast_MRI_921', 'Breast_MRI_922'],\n",
       "      dtype='object', name='Patient ID', length=922)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yflags.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yflags['StagingNodes']['Breast_MRI_014'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.isnan(yflags['StagingNodes']['Breast_MRI_016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 31,\n",
       " 63,\n",
       " 65,\n",
       " 80,\n",
       " 122,\n",
       " 140,\n",
       " 238,\n",
       " 322,\n",
       " 386,\n",
       " 394,\n",
       " 401,\n",
       " 406,\n",
       " 535,\n",
       " 574,\n",
       " 637,\n",
       " 646,\n",
       " 674,\n",
       " 704,\n",
       " 743,\n",
       " 814,\n",
       " 861,\n",
       " 876,\n",
       " 906]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i+1 for i in range(len(yflags['StagingNodes'])) if np.isnan(yflags['StagingNodes'][i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientData=[]\n",
    "patientIndices=[]\n",
    "patientDimensions=[]\n",
    "\n",
    "inputData='data/firstpass_923_cropped.h5'\n",
    "\n",
    "\n",
    "with h5py.File(inputData, 'r') as f:\n",
    "    # Iterate over the groups in the file\n",
    "    for key in f.keys():\n",
    "        #print(f\"key\\t{key}\")\n",
    "        patientIndices.append(int(key))\n",
    "        # Get the group\n",
    "        grp = f[key]\n",
    "        # Get the array dimensions\n",
    "        shape = grp.attrs['shape']\n",
    "        patientDimensions.append(shape)\n",
    "        # Read the array data (decompression happens automatically)\n",
    "        \n",
    "        #arr = grp['data'][:]\n",
    "\n",
    "        #patientData.append(grp['data'][:])\n",
    "        # Use arr for further processing\n",
    "patientDimensions=np.asarray(patientDimensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([171., 471., 483.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgShape=patientDimensions.mean(axis=0)\n",
    "imgShape=np.round(avgShape)\n",
    "imgShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###try resize+resave for compression\n",
    "\n",
    "\n",
    "inputData='data/firstpass_923.h5'\n",
    "hfile=h5py.File(inputData,\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=hfile['21']['data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 512, 512)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,ys,zs = np.where(arr!=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 192], [0, 466], [0, 512]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundingBox=[[np.min(xs),np.max(xs)+1],[np.min(ys),np.max(ys)+1],[np.min(zs),np.max(zs)+1]]\n",
    "boundingBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### first do zero slicing, \n",
    "boundingBoxes=[]\n",
    "\n",
    "for i in arr:\n",
    "    xs,ys= np.where(i!=0) \n",
    "    boundingBoxes.append([[min(xs),max(xs)+1],[min(ys),max(ys)+1]])\n",
    "    \n",
    "\n",
    "#then we can resize and such\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### go through, grab the bounding boxes -- crop and save h5\n",
    "boundBoxFinals=[]\n",
    "\n",
    "inputData='data/firstpass_923.h5'\n",
    "outputFile='data/firstpass_testCrop_03thresh.h5'\n",
    "lowerBound=.03\n",
    "checkKeys=[19, 20, 30, 21, 29, 25, 26, 18]\n",
    "\n",
    "\n",
    "with h5py.File(f'{outputFile}','w') as patientData:\n",
    "    with h5py.File(inputData, 'r') as f:\n",
    "        for key in set(f.keys()) & {str(k) for k in checkKeys}:\n",
    "            \n",
    "            arr=f[key]['data'][:]\n",
    "            #xs,ys,zs = np.where(arr!=0)\n",
    "            xs,ys,zs = np.where(arr>lowerBound)  \n",
    "            boundingBox=boundingBox=[[np.min(xs),np.max(xs)+1],[np.min(ys),np.max(ys)+1],[np.min(zs),np.max(zs)+1]]\n",
    "            boundBoxFinals.append(boundingBox)\n",
    "\n",
    "            grp=patientData.create_group(key)\n",
    "            result=arr[boundingBox[0][0]:boundingBox[0][1],boundingBox[1][0]:boundingBox[1][1],boundingBox[2][0]:boundingBox[2][1]]\n",
    "            grp.attrs['shape']=result.shape\n",
    "            grp.create_dataset('data',data=result.astype(np.float16),compression=\"gzip\", compression_opts=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### go through, grab the bounding boxes -- crop and save h5\n",
    "boundBoxFinals=[]\n",
    "\n",
    "inputData='data/firstpass_923.h5'\n",
    "\n",
    "lowerBound=.15\n",
    "outputFile=f'data/firstpass_923_cropped_point{lowerBound*100}Thresh.h5'\n",
    "checkKeys=[19, 20, 30, 21, 29, 25, 26, 18]\n",
    "\n",
    "\n",
    "with h5py.File(f'{outputFile}','w') as patientData:\n",
    "    with h5py.File(inputData, 'r') as f:\n",
    "        for key in f.keys():\n",
    "            \n",
    "            arr=f[key]['data'][:]\n",
    "            #xs,ys,zs = np.where(arr!=0)\n",
    "            xs,ys,zs = np.where(arr>lowerBound)  \n",
    "            boundingBox=boundingBox=[[np.min(xs),np.max(xs)+1],[np.min(ys),np.max(ys)+1],[np.min(zs),np.max(zs)+1]]\n",
    "            boundBoxFinals.append(boundingBox)\n",
    "\n",
    "            grp=patientData.create_group(key)\n",
    "            result=arr[boundingBox[0][0]:boundingBox[0][1],boundingBox[1][0]:boundingBox[1][1],boundingBox[2][0]:boundingBox[2][1]]\n",
    "            grp.attrs['shape']=result.shape\n",
    "            grp.create_dataset('data',data=result.astype(np.float16),compression=\"gzip\", compression_opts=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##resize\n",
    "boundBoxFinals=np.asarray(boundBoxFinals)\n",
    "avgShape=boundBoxFinals.mean(axis=0)\n",
    "imgSize=np.round(avgShape)\n",
    "transform=Compose([Resize(spatial_size=imgSize)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2., 169.],\n",
       "       [ 56., 414.],\n",
       "       [  8., 479.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4., 167.],\n",
       "       [ 73., 407.],\n",
       "       [ 12., 476.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgSize#new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([167., 358., 471.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resizeAvg=imgSize[:,1]-imgSize[:,0]\n",
    "resizeAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([163., 334., 464.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resizeAvg=imgSize[:,1]-imgSize[:,0]\n",
    "resizeAvg #new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 171.],\n",
       "       [  5., 476.],\n",
       "       [  2., 485.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgSize ## old imgSize -> [0,171 , 5-476 , 2-485]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now let's resize the data and save to one final h5 file for the pipeline\n",
    "\n",
    "##resize\n",
    "imgSize=np.array([163., 334., 464.]) ## retrieved from first read block or rounded average of grp[shape]\n",
    "downSample=2.0\n",
    "imgSize=np.round(imgSize/downSample)\n",
    "\n",
    "#transform=Compose([Resize(spatial_size=imgSize)])\n",
    "transform=Compose([Resize(spatial_size=[23,47,66])]) \n",
    "\n",
    "#outputFile=f'data/firstpass_923_cropped_point{lowerBound*100}Thresh.h5'\n",
    "#firstN=10\n",
    "checkKeys=[19, 20, 30, 21, 29, 25, 26, 18]\n",
    "\n",
    "lowerBound=.20\n",
    "inputData=f'data/firstpass_923_cropped_point{lowerBound*100}Thresh.h5'\n",
    "#outputFile=f'data/firstpass_923_avgCropResize_DS{int(downSample*10)}_point{int(lowerBound*100)}Thresh_subSample.h5'\n",
    "outputFile=f'data/firstpass_923_avgCropResize_DS70_point{int(lowerBound*100)}Thresh_subSample.h5'\n",
    "\n",
    "with h5py.File(f'{outputFile}','w') as patientData:\n",
    "    with h5py.File(inputData, 'r') as f:\n",
    "        for key in set(f.keys()) & {str(k) for k in checkKeys}:\n",
    "            arr=f[key]['data'][:]\n",
    "            volume=torch.tensor(arr).unsqueeze(0)\n",
    "            volume=transform(volume)\n",
    "            grp=patientData.create_group(key)\n",
    "            grp.attrs['shape']=imgSize\n",
    "            images=volume[:].numpy().astype(np.float16)\n",
    "            images=(images-images.min())/(images.max()-images.min())\n",
    "\n",
    "            grp.create_dataset('data',data=images.astype(np.float16),compression=\"gzip\", compression_opts=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now let's resize the data and save to one final h5 file for the pipeline\n",
    "\n",
    "##resize\n",
    "imgSize=np.array([163., 334., 464.]) ## retrieved from first read block or rounded average of grp[shape]\n",
    "downSample=3.0\n",
    "imgSize=np.round(imgSize/downSample)\n",
    "\n",
    "transform=Compose([Resize(spatial_size=imgSize)])\n",
    "#transform=Compose([Resize(spatial_size=[23,47,66])]) \n",
    "\n",
    "#outputFile=f'data/firstpass_923_cropped_point{lowerBound*100}Thresh.h5'\n",
    "#firstN=10\n",
    "checkKeys=[19, 20, 30, 21, 29, 25, 26, 18]\n",
    "\n",
    "lowerBound=.20\n",
    "inputData=f'data/firstpass_923_cropped_point{lowerBound*100}Thresh.h5'\n",
    "#outputFile=f'data/firstpass_923_avgCropResize_DS{int(downSample*10)}_point{int(lowerBound*100)}Thresh_subSample.h5'\n",
    "outputFile=f'data/firstpass_923_avgCropResize_DS{downSample*10}_point{int(lowerBound*100)}Thresh.h5'\n",
    "\n",
    "with h5py.File(f'{outputFile}','w') as patientData:\n",
    "    with h5py.File(inputData, 'r') as f:\n",
    "        for key in f.keys():\n",
    "            arr=f[key]['data'][:]\n",
    "            volume=torch.tensor(arr).unsqueeze(0)\n",
    "            volume=transform(volume)\n",
    "            grp=patientData.create_group(key)\n",
    "            grp.attrs['shape']=imgSize\n",
    "            images=volume[:].numpy().astype(np.float16)\n",
    "            images=(images-images.min())/(images.max()-images.min())\n",
    "\n",
    "            grp.create_dataset('data',data=images.astype(np.float16),compression=\"gzip\", compression_opts=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now let's resize the data and save to one final h5 file for the pipeline\n",
    "\n",
    "##resize\n",
    "imgSize=np.array([167., 358., 471.]) ## retrieved from first read block or rounded average of grp[shape]\n",
    "downSample=2.0\n",
    "imgSize=np.round(imgSize/downSample)\n",
    "\n",
    "transform=Compose([Resize(spatial_size=imgSize)])\n",
    "\n",
    "\n",
    "#outputFile=f'data/firstpass_923_cropped_point{lowerBound*100}Thresh.h5'\n",
    "#firstN=10\n",
    "checkKeys=[19, 20, 30, 21, 29, 25, 26, 18]\n",
    "\n",
    "lowerBound=.15\n",
    "inputData=f'data/firstpass_923_cropped_point{lowerBound*100}Thresh.h5'\n",
    "outputFile=f'data/firstpass_923_avgCropResize_DS{int(downSample*10)}_point{int(lowerBound*100)}Thresh.h5'\n",
    "\n",
    "with h5py.File(f'{outputFile}','w') as patientData:\n",
    "    with h5py.File(inputData, 'r') as f:\n",
    "        for key in f.keys() :\n",
    "            arr=f[key]['data'][:]\n",
    "            volume=torch.tensor(arr).unsqueeze(0)\n",
    "            volume=transform(volume)\n",
    "            grp=patientData.create_group(key)\n",
    "            grp.attrs['shape']=imgSize\n",
    "            images=volume[:].numpy().astype(np.float16)\n",
    "            images=(images-images.min())/(images.max()-images.min())\n",
    "\n",
    "            grp.create_dataset('data',data=images.astype(np.float16),compression=\"gzip\", compression_opts=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now let's resize the data and save to one final h5 file for the pipeline\n",
    "\n",
    "##resize\n",
    "imgSize=np.array([163., 334., 464.]) ## retrieved from first read block or rounded average of grp[shape]\n",
    "downSample=2.0\n",
    "imgSize=np.round(imgSize/downSample)\n",
    "\n",
    "transform=Compose([Resize(spatial_size=imgSize)])\n",
    "\n",
    "\n",
    "#outputFile=f'data/firstpass_923_cropped_point{lowerBound*100}Thresh.h5'\n",
    "#firstN=10\n",
    "checkKeys=[19, 20, 30, 21, 29, 25, 26, 18]\n",
    "\n",
    "lowerBound=.20\n",
    "inputData=f'data/firstpass_923_cropped_point{lowerBound*100}Thresh.h5'\n",
    "outputFile=f'data/firstpass_923_avgCropResize_DS{int(downSample*10)}_point{int(lowerBound*100)}Thresh.h5'\n",
    "\n",
    "with h5py.File(f'{outputFile}','w') as patientData:\n",
    "    with h5py.File(inputData, 'r') as f:\n",
    "        for key in f.keys() :\n",
    "            arr=f[key]['data'][:]\n",
    "            volume=torch.tensor(arr).unsqueeze(0)\n",
    "            volume=transform(volume)\n",
    "            grp=patientData.create_group(key)\n",
    "            grp.attrs['shape']=imgSize\n",
    "            images=volume[:].numpy().astype(np.float16)\n",
    "            images=(images-images.min())/(images.max()-images.min())\n",
    "\n",
    "            grp.create_dataset('data',data=images.astype(np.float16),compression=\"gzip\", compression_opts=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with h5py.File(outputFile, 'r') as f:\n",
    "    arr=f['19']['data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 83, 179, 235)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now let's resize the data and save to one final h5 file for the pipeline\n",
    "\n",
    "##resize\n",
    "imgSize=[171,471,483] ## retrieved from first read block or rounded average of grp[shape]\n",
    "transform=Compose([Resize(spatial_size=imgSize)])\n",
    "\n",
    "\n",
    "#firstN=10\n",
    "checkKeys=[19, 20, 30, 21, 29, 25, 26, 18]\n",
    "\n",
    "\n",
    "inputData='data/firstpass_923_cropped.h5'\n",
    "outputFile=f'data/firstpass_923_avgCropResize.h5'\n",
    "\n",
    "with h5py.File(f'{outputFile}','w') as patientData:\n",
    "    with h5py.File(inputData, 'r') as f:\n",
    "        for key in set(f.keys()):\n",
    "            arr=f[key]['data'][:]\n",
    "            volume=torch.tensor(arr).unsqueeze(0)\n",
    "            volume=transform(volume)\n",
    "            grp=patientData.create_group(key)\n",
    "            grp.attrs['shape']=imgSize\n",
    "            images=volume[:].numpy().astype(np.float16)\n",
    "            images=(images-images.min())/(images.max()-images.min())\n",
    "\n",
    "            grp.create_dataset('data',data=images.astype(np.float16),compression=\"gzip\", compression_opts=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'597'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 512, 512)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 171.],\n",
       "       [  5., 476.],\n",
       "       [  2., 485.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.spatial.array.Resize object at 0x000001C0E3295A90>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\transform.py:141\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items, lazy, overrides, log_stats) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\transform.py:98\u001b[0m, in \u001b[0;36m_apply_transform\u001b[1;34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transform(data, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(data)\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\spatial\\array.py:821\u001b[0m, in \u001b[0;36mResize.__call__\u001b[1;34m(self, img, mode, align_corners, anti_aliasing, anti_aliasing_sigma, dtype, lazy)\u001b[0m\n\u001b[0;32m    820\u001b[0m     _sp \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpeek_pending_shape() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, MetaTensor) \u001b[38;5;28;01melse\u001b[39;00m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 821\u001b[0m     sp_size \u001b[38;5;241m=\u001b[39m fall_back_tuple(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_size, _sp)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# for the \"longest\" mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\utils\\misc.py:280\u001b[0m, in \u001b[0;36mfall_back_tuple\u001b[1;34m(user_provided, default, func)\u001b[0m\n\u001b[0;32m    279\u001b[0m user \u001b[38;5;241m=\u001b[39m ensure_tuple_rep(user_provided, ndim)\n\u001b[1;32m--> 280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(  \u001b[38;5;66;03m# use the default values if user provided is not valid\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     user_c \u001b[38;5;28;01mif\u001b[39;00m func(user_c) \u001b[38;5;28;01melse\u001b[39;00m default_c \u001b[38;5;28;01mfor\u001b[39;00m default_c, user_c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(default, user)\n\u001b[0;32m    282\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\utils\\misc.py:281\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    279\u001b[0m user \u001b[38;5;241m=\u001b[39m ensure_tuple_rep(user_provided, ndim)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(  \u001b[38;5;66;03m# use the default values if user provided is not valid\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m     user_c \u001b[38;5;28;01mif\u001b[39;00m func(user_c) \u001b[38;5;28;01melse\u001b[39;00m default_c \u001b[38;5;28;01mfor\u001b[39;00m default_c, user_c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(default, user)\n\u001b[0;32m    282\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\utils\\misc.py:240\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m({k: v[ik] \u001b[38;5;28;01mfor\u001b[39;00m (k, v) \u001b[38;5;129;01min\u001b[39;00m dict_overrides\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m ik \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(keys)))\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfall_back_tuple\u001b[39m(\n\u001b[1;32m--> 240\u001b[0m     user_provided: Any, default: Sequence \u001b[38;5;241m|\u001b[39m NdarrayTensor, func: Callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;129;01mand\u001b[39;00m x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    241\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    Refine `user_provided` according to the `default`, and returns as a validated tuple.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'list' and 'int'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m transform(volume)\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\compose.py:335\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, input_, start, end, threading, lazy)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, threading\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, lazy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    334\u001b[0m     _lazy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lazy\n\u001b[1;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m execute_compose(\n\u001b[0;32m    336\u001b[0m         input_,\n\u001b[0;32m    337\u001b[0m         transforms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms,\n\u001b[0;32m    338\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    339\u001b[0m         end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    340\u001b[0m         map_items\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_items,\n\u001b[0;32m    341\u001b[0m         unpack_items\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpack_items,\n\u001b[0;32m    342\u001b[0m         lazy\u001b[38;5;241m=\u001b[39m_lazy,\n\u001b[0;32m    343\u001b[0m         overrides\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides,\n\u001b[0;32m    344\u001b[0m         threading\u001b[38;5;241m=\u001b[39mthreading,\n\u001b[0;32m    345\u001b[0m         log_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_stats,\n\u001b[0;32m    346\u001b[0m     )\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\compose.py:111\u001b[0m, in \u001b[0;36mexecute_compose\u001b[1;34m(data, transforms, map_items, unpack_items, start, end, lazy, overrides, threading, log_stats)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threading:\n\u001b[0;32m    110\u001b[0m         _transform \u001b[38;5;241m=\u001b[39m deepcopy(_transform) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_transform, ThreadUnsafe) \u001b[38;5;28;01melse\u001b[39;00m _transform\n\u001b[1;32m--> 111\u001b[0m     data \u001b[38;5;241m=\u001b[39m apply_transform(\n\u001b[0;32m    112\u001b[0m         _transform, data, map_items, unpack_items, lazy\u001b[38;5;241m=\u001b[39mlazy, overrides\u001b[38;5;241m=\u001b[39moverrides, log_stats\u001b[38;5;241m=\u001b[39mlog_stats\n\u001b[0;32m    113\u001b[0m     )\n\u001b[0;32m    114\u001b[0m data \u001b[38;5;241m=\u001b[39m apply_pending_transforms(data, \u001b[38;5;28;01mNone\u001b[39;00m, overrides, logger_name\u001b[38;5;241m=\u001b[39mlog_stats)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\transform.py:171\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m         _log_stats(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplying transform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransform\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: applying transform <monai.transforms.spatial.array.Resize object at 0x000001C0E3295A90>"
     ]
    }
   ],
   "source": [
    "transform(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "np.random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### let's do k-fold samples and just store \n",
    "\n",
    "\n",
    "def kFold_TrainTestSplit(arr,k:int,testP=.1,shuffle=True):\n",
    "    assert len(arr)>1 and testP<=1\n",
    "    folds=[] # [([...Tr_k...],[...Te_k...])]\n",
    "    testSize=round(testP*len(arr))\n",
    "    \n",
    "    for i in range(k):\n",
    "        testBin=list(np.random.choice(arr,size=testSize,replace=False,))\n",
    "        trainBin=list(set(arr)-set(testBin))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(testBin)\n",
    "            np.random.shuffle(trainBin)\n",
    "        folds.append({\"train\":trainBin,\"test\":testBin})\n",
    "\n",
    "    return folds\n",
    "\n",
    "def gen_kFold_TrainTestSplit(arr,k,trP,fileName=\"kFoldGen.sav\"):\n",
    "    folds=kFold_TrainTestSplit(arr,k,trP)\n",
    "    joblib.dump(folds,fileName)\n",
    "\n",
    "def load_kFold_TrainTestSplit(fileName=\"kFoldGen.sav\"):\n",
    "    \"\"\"\n",
    "    returns a list of size k:\n",
    "    [{\"train\":[tr_k],\"test\":[te_k]},...]\n",
    "    \"\"\"\n",
    "    \n",
    "    return joblib.load(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[int(i.split(\"_\")[-1]) for i in yflags.index]\n",
    "k=5\n",
    "trP=.8\n",
    "folds=kFold_TrainTestSplit(arr,k,trP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[503,\n",
       " 359,\n",
       " 241,\n",
       " 8,\n",
       " 358,\n",
       " 589,\n",
       " 222,\n",
       " 460,\n",
       " 838,\n",
       " 843,\n",
       " 510,\n",
       " 718,\n",
       " 831,\n",
       " 255,\n",
       " 613,\n",
       " 276,\n",
       " 320,\n",
       " 259,\n",
       " 292,\n",
       " 11,\n",
       " 727,\n",
       " 570,\n",
       " 475,\n",
       " 92,\n",
       " 904,\n",
       " 51,\n",
       " 192,\n",
       " 286,\n",
       " 190,\n",
       " 498,\n",
       " 794,\n",
       " 451,\n",
       " 429,\n",
       " 744,\n",
       " 24,\n",
       " 487,\n",
       " 868,\n",
       " 733,\n",
       " 213,\n",
       " 324,\n",
       " 64,\n",
       " 80,\n",
       " 670,\n",
       " 906,\n",
       " 913,\n",
       " 578,\n",
       " 84,\n",
       " 137,\n",
       " 731,\n",
       " 644,\n",
       " 177,\n",
       " 619,\n",
       " 146,\n",
       " 754,\n",
       " 119,\n",
       " 171,\n",
       " 792,\n",
       " 357,\n",
       " 550,\n",
       " 120,\n",
       " 147,\n",
       " 604,\n",
       " 333,\n",
       " 797,\n",
       " 561,\n",
       " 698,\n",
       " 207,\n",
       " 894,\n",
       " 469,\n",
       " 618,\n",
       " 138,\n",
       " 430,\n",
       " 655,\n",
       " 634,\n",
       " 38,\n",
       " 339,\n",
       " 149,\n",
       " 919,\n",
       " 809,\n",
       " 784,\n",
       " 688,\n",
       " 226,\n",
       " 194,\n",
       " 53,\n",
       " 855,\n",
       " 737,\n",
       " 321,\n",
       " 785,\n",
       " 679,\n",
       " 375,\n",
       " 351,\n",
       " 159,\n",
       " 220,\n",
       " 354,\n",
       " 87,\n",
       " 872,\n",
       " 424,\n",
       " 649,\n",
       " 41,\n",
       " 810,\n",
       " 743,\n",
       " 710,\n",
       " 422,\n",
       " 114,\n",
       " 389,\n",
       " 630,\n",
       " 291,\n",
       " 862,\n",
       " 158,\n",
       " 385,\n",
       " 769,\n",
       " 314,\n",
       " 876,\n",
       " 676,\n",
       " 157,\n",
       " 645,\n",
       " 738,\n",
       " 326,\n",
       " 828,\n",
       " 23,\n",
       " 911,\n",
       " 827,\n",
       " 221,\n",
       " 572,\n",
       " 135,\n",
       " 593,\n",
       " 605,\n",
       " 100,\n",
       " 262,\n",
       " 563,\n",
       " 842,\n",
       " 340,\n",
       " 132,\n",
       " 25,\n",
       " 322,\n",
       " 646,\n",
       " 341,\n",
       " 180,\n",
       " 699,\n",
       " 250,\n",
       " 150,\n",
       " 559,\n",
       " 562,\n",
       " 471,\n",
       " 753,\n",
       " 270,\n",
       " 607,\n",
       " 69,\n",
       " 365,\n",
       " 77,\n",
       " 793,\n",
       " 590,\n",
       " 170,\n",
       " 443,\n",
       " 142,\n",
       " 232,\n",
       " 689,\n",
       " 878,\n",
       " 323,\n",
       " 305,\n",
       " 757,\n",
       " 26,\n",
       " 373,\n",
       " 345,\n",
       " 480,\n",
       " 94,\n",
       " 780,\n",
       " 386,\n",
       " 547,\n",
       " 621,\n",
       " 790,\n",
       " 692,\n",
       " 626,\n",
       " 398,\n",
       " 457,\n",
       " 450,\n",
       " 308,\n",
       " 800,\n",
       " 63,\n",
       " 695,\n",
       " 513,\n",
       " 796,\n",
       " 497,\n",
       " 310,\n",
       " 766,\n",
       " 168,\n",
       " 195,\n",
       " 238,\n",
       " 732,\n",
       " 632,\n",
       " 750,\n",
       " 296,\n",
       " 218,\n",
       " 281,\n",
       " 412,\n",
       " 110,\n",
       " 534,\n",
       " 229,\n",
       " 56,\n",
       " 657,\n",
       " 79,\n",
       " 909,\n",
       " 362,\n",
       " 348,\n",
       " 101,\n",
       " 529,\n",
       " 584,\n",
       " 840,\n",
       " 458,\n",
       " 108,\n",
       " 81,\n",
       " 496,\n",
       " 230,\n",
       " 658,\n",
       " 735,\n",
       " 708,\n",
       " 601,\n",
       " 615,\n",
       " 845,\n",
       " 488,\n",
       " 798,\n",
       " 293,\n",
       " 13,\n",
       " 61,\n",
       " 301,\n",
       " 616,\n",
       " 921,\n",
       " 778,\n",
       " 706,\n",
       " 133,\n",
       " 151,\n",
       " 206,\n",
       " 514,\n",
       " 411,\n",
       " 16,\n",
       " 49,\n",
       " 165,\n",
       " 197,\n",
       " 721,\n",
       " 237,\n",
       " 711,\n",
       " 819,\n",
       " 659,\n",
       " 328,\n",
       " 580,\n",
       " 671,\n",
       " 251,\n",
       " 353,\n",
       " 346,\n",
       " 549,\n",
       " 536,\n",
       " 832,\n",
       " 52,\n",
       " 672,\n",
       " 141,\n",
       " 663,\n",
       " 330,\n",
       " 920,\n",
       " 434,\n",
       " 786,\n",
       " 722,\n",
       " 853,\n",
       " 85,\n",
       " 193,\n",
       " 863,\n",
       " 337,\n",
       " 402,\n",
       " 815,\n",
       " 307,\n",
       " 814,\n",
       " 265,\n",
       " 1,\n",
       " 787,\n",
       " 304,\n",
       " 771,\n",
       " 428,\n",
       " 104,\n",
       " 209,\n",
       " 234,\n",
       " 111,\n",
       " 446,\n",
       " 478,\n",
       " 431,\n",
       " 432,\n",
       " 472,\n",
       " 253,\n",
       " 528,\n",
       " 772,\n",
       " 36,\n",
       " 922,\n",
       " 686,\n",
       " 799,\n",
       " 319,\n",
       " 5,\n",
       " 342,\n",
       " 394,\n",
       " 889,\n",
       " 554,\n",
       " 493,\n",
       " 741,\n",
       " 587,\n",
       " 499,\n",
       " 160,\n",
       " 505,\n",
       " 844,\n",
       " 267,\n",
       " 756,\n",
       " 65,\n",
       " 331,\n",
       " 556,\n",
       " 99,\n",
       " 541,\n",
       " 297,\n",
       " 393,\n",
       " 902,\n",
       " 884,\n",
       " 78,\n",
       " 271,\n",
       " 71,\n",
       " 82,\n",
       " 367,\n",
       " 532,\n",
       " 186,\n",
       " 581,\n",
       " 839,\n",
       " 782,\n",
       " 247,\n",
       " 300,\n",
       " 364,\n",
       " 360,\n",
       " 179,\n",
       " 89,\n",
       " 175,\n",
       " 484,\n",
       " 654,\n",
       " 685,\n",
       " 181,\n",
       " 347,\n",
       " 349,\n",
       " 873,\n",
       " 622,\n",
       " 7,\n",
       " 59,\n",
       " 817,\n",
       " 734,\n",
       " 152,\n",
       " 870,\n",
       " 713,\n",
       " 781,\n",
       " 789,\n",
       " 703,\n",
       " 219,\n",
       " 625,\n",
       " 729,\n",
       " 694,\n",
       " 116,\n",
       " 504,\n",
       " 714,\n",
       " 558,\n",
       " 675,\n",
       " 22,\n",
       " 75,\n",
       " 763,\n",
       " 749,\n",
       " 567,\n",
       " 739,\n",
       " 318,\n",
       " 67,\n",
       " 697,\n",
       " 597,\n",
       " 515,\n",
       " 866,\n",
       " 384,\n",
       " 37,\n",
       " 203,\n",
       " 807,\n",
       " 826,\n",
       " 316,\n",
       " 856,\n",
       " 46,\n",
       " 752,\n",
       " 139,\n",
       " 315,\n",
       " 126,\n",
       " 33,\n",
       " 275,\n",
       " 88,\n",
       " 356,\n",
       " 408,\n",
       " 136,\n",
       " 445,\n",
       " 309,\n",
       " 129,\n",
       " 575,\n",
       " 173,\n",
       " 811,\n",
       " 256,\n",
       " 606,\n",
       " 284,\n",
       " 311,\n",
       " 465,\n",
       " 156,\n",
       " 812,\n",
       " 383,\n",
       " 511,\n",
       " 887,\n",
       " 642,\n",
       " 858,\n",
       " 804,\n",
       " 765,\n",
       " 166,\n",
       " 303,\n",
       " 573,\n",
       " 123,\n",
       " 677,\n",
       " 382,\n",
       " 633,\n",
       " 822,\n",
       " 818,\n",
       " 609,\n",
       " 243,\n",
       " 153,\n",
       " 758,\n",
       " 4,\n",
       " 433,\n",
       " 603,\n",
       " 107,\n",
       " 875,\n",
       " 73,\n",
       " 516,\n",
       " 726,\n",
       " 201,\n",
       " 624,\n",
       " 410,\n",
       " 249,\n",
       " 182,\n",
       " 399,\n",
       " 614,\n",
       " 849,\n",
       " 551,\n",
       " 406,\n",
       " 495,\n",
       " 374,\n",
       " 883,\n",
       " 696,\n",
       " 442,\n",
       " 462,\n",
       " 325,\n",
       " 836,\n",
       " 545,\n",
       " 3,\n",
       " 557,\n",
       " 764,\n",
       " 299,\n",
       " 285,\n",
       " 595,\n",
       " 880,\n",
       " 574,\n",
       " 95,\n",
       " 776,\n",
       " 105,\n",
       " 355,\n",
       " 864,\n",
       " 566,\n",
       " 662,\n",
       " 628,\n",
       " 535,\n",
       " 569,\n",
       " 125,\n",
       " 717,\n",
       " 43,\n",
       " 635,\n",
       " 29,\n",
       " 148,\n",
       " 361,\n",
       " 416,\n",
       " 106,\n",
       " 577,\n",
       " 9,\n",
       " 425,\n",
       " 400,\n",
       " 278,\n",
       " 414,\n",
       " 298,\n",
       " 476,\n",
       " 109,\n",
       " 128,\n",
       " 418,\n",
       " 903,\n",
       " 200,\n",
       " 174,\n",
       " 543,\n",
       " 306,\n",
       " 50,\n",
       " 837,\n",
       " 70,\n",
       " 167,\n",
       " 521,\n",
       " 274,\n",
       " 530,\n",
       " 93,\n",
       " 681,\n",
       " 774,\n",
       " 27,\n",
       " 420,\n",
       " 246,\n",
       " 202,\n",
       " 900,\n",
       " 448,\n",
       " 407,\n",
       " 740,\n",
       " 746,\n",
       " 901,\n",
       " 30,\n",
       " 90,\n",
       " 548,\n",
       " 388,\n",
       " 833,\n",
       " 479,\n",
       " 648,\n",
       " 907,\n",
       " 258,\n",
       " 390,\n",
       " 244,\n",
       " 485,\n",
       " 527,\n",
       " 68,\n",
       " 687,\n",
       " 490,\n",
       " 712,\n",
       " 76,\n",
       " 761,\n",
       " 35,\n",
       " 118,\n",
       " 891,\n",
       " 690,\n",
       " 289,\n",
       " 885,\n",
       " 851,\n",
       " 779,\n",
       " 421,\n",
       " 568,\n",
       " 742,\n",
       " 210,\n",
       " 816,\n",
       " 184,\n",
       " 387,\n",
       " 277,\n",
       " 42,\n",
       " 652,\n",
       " 83,\n",
       " 537,\n",
       " 55,\n",
       " 538,\n",
       " 31,\n",
       " 378,\n",
       " 916,\n",
       " 426,\n",
       " 560,\n",
       " 859,\n",
       " 720,\n",
       " 96,\n",
       " 611,\n",
       " 608,\n",
       " 582,\n",
       " 40,\n",
       " 519,\n",
       " 808,\n",
       " 288,\n",
       " 664,\n",
       " 820,\n",
       " 32,\n",
       " 598,\n",
       " 591,\n",
       " 693,\n",
       " 531,\n",
       " 857,\n",
       " 344,\n",
       " 379,\n",
       " 518,\n",
       " 867,\n",
       " 823,\n",
       " 627,\n",
       " 747,\n",
       " 122,\n",
       " 517,\n",
       " 791,\n",
       " 343,\n",
       " 130,\n",
       " 224,\n",
       " 874,\n",
       " 191,\n",
       " 861,\n",
       " 723,\n",
       " 427,\n",
       " 544,\n",
       " 912,\n",
       " 282,\n",
       " 893,\n",
       " 770,\n",
       " 18,\n",
       " 638,\n",
       " 198,\n",
       " 66,\n",
       " 700,\n",
       " 835,\n",
       " 233,\n",
       " 667,\n",
       " 463,\n",
       " 172,\n",
       " 724,\n",
       " 586,\n",
       " 372,\n",
       " 491,\n",
       " 600,\n",
       " 854,\n",
       " 502,\n",
       " 121,\n",
       " 57,\n",
       " 338,\n",
       " 417,\n",
       " 879,\n",
       " 788,\n",
       " 483,\n",
       " 669,\n",
       " 666,\n",
       " 45,\n",
       " 287,\n",
       " 405,\n",
       " 620,\n",
       " 552,\n",
       " 266,\n",
       " 470,\n",
       " 631,\n",
       " 783,\n",
       " 336,\n",
       " 539,\n",
       " 684,\n",
       " 14,\n",
       " 508,\n",
       " 683,\n",
       " 588,\n",
       " 647,\n",
       " 113,\n",
       " 602,\n",
       " 10,\n",
       " 653,\n",
       " 204,\n",
       " 461,\n",
       " 185,\n",
       " 641,\n",
       " 650,\n",
       " 441,\n",
       " 392,\n",
       " 103,\n",
       " 97,\n",
       " 369,\n",
       " 143,\n",
       " 571,\n",
       " 673,\n",
       " 225,\n",
       " 846,\n",
       " 279,\n",
       " 892,\n",
       " 74,\n",
       " 506,\n",
       " 449,\n",
       " 869,\n",
       " 366,\n",
       " 169,\n",
       " 208,\n",
       " 117,\n",
       " 272,\n",
       " 660,\n",
       " 824,\n",
       " 178,\n",
       " 918,\n",
       " 395,\n",
       " 777,\n",
       " 526,\n",
       " 423,\n",
       " 466,\n",
       " 617,\n",
       " 501,\n",
       " 217,\n",
       " 525,\n",
       " 352,\n",
       " 370,\n",
       " 897,\n",
       " 898,\n",
       " 592,\n",
       " 678,\n",
       " 636,\n",
       " 183,\n",
       " 895,\n",
       " 736,\n",
       " 481,\n",
       " 680,\n",
       " 795,\n",
       " 131,\n",
       " 716,\n",
       " 48,\n",
       " 264,\n",
       " 413,\n",
       " 806,\n",
       " 522,\n",
       " 436,\n",
       " 199,\n",
       " 72,\n",
       " 492,\n",
       " 317,\n",
       " 665,\n",
       " 187,\n",
       " 19,\n",
       " 290,\n",
       " 196,\n",
       " 801,\n",
       " 58,\n",
       " 834,\n",
       " 594,\n",
       " 154,\n",
       " 115,\n",
       " 216,\n",
       " 377,\n",
       " 830,\n",
       " 682,\n",
       " 102,\n",
       " 161,\n",
       " 438,\n",
       " 127,\n",
       " 829,\n",
       " 12,\n",
       " 28,\n",
       " 865,\n",
       " 86,\n",
       " 280,\n",
       " 494,\n",
       " 257]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds[1]['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(i.split(\"_\")[-1]) for i in yflags.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### let's do k-fold samples and just store \n",
    "\n",
    "\n",
    "def kFold_TrainTestSplit(arr,k:int,testP=.1,shuffle=True):\n",
    "    assert len(arr)>1 and testP<=1\n",
    "    folds=[] # [([...Tr_k...],[...Te_k...])]\n",
    "    testSize=round(testP*len(arr))\n",
    "    \n",
    "    for i in range(k):\n",
    "        testBin=list(np.random.choice(arr,size=testSize,replace=False,))\n",
    "        trainBin=list(set(arr)-set(testBin))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(testBin)\n",
    "            np.random.shuffle(trainBin)\n",
    "        folds.append({\"train\":trainBin,\"test\":testBin})\n",
    "\n",
    "    return folds\n",
    "\n",
    "def gen_kFold_TrainTestSplit(arr,k,trP,fileName=\"kFoldGen.sav\"):\n",
    "    folds=kFold_TrainTestSplit(arr,k,trP)\n",
    "    joblib.dump(folds,fileName)\n",
    "\n",
    "def load_kFold_TrainTestSplit(fileName=\"kFoldGen.sav\"):\n",
    "    \"\"\"\n",
    "    returns a list of size k:\n",
    "    [{\"train\":[tr_k],\"test\":[te_k]},...]\n",
    "    \"\"\"\n",
    "    \n",
    "    return joblib.load(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda=torch.cuda.is_available()\n",
    "\n",
    "\n",
    "\n",
    "pretrain_batchsize = 5\n",
    "channels=3\n",
    "# Data augmentation (on-the-fly) parameters\n",
    "aug_prob = 1\n",
    "rand_rot = 10                       # random rotation range [deg]\n",
    "rand_rot_rad = rand_rot*math.pi/180 # random rotation range [rad]\n",
    "rand_noise_std = 0.01               # std random Gaussian noise\n",
    "rand_shift = 5                      # px random shift\n",
    "min_zoom = 0.9\n",
    "max_zoom = 1.1\n",
    "\n",
    "\n",
    "useGPU=True\n",
    "batchSize=25\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def kFold_TrainTestSplit(arr,k:int,testP=.1,shuffle=True):\n",
    "    assert len(arr)>1 and testP<=1\n",
    "    folds=[] # [([...Tr_k...],[...Te_k...])]\n",
    "    testSize=round(testP*len(arr))\n",
    "    \n",
    "    for i in range(k):\n",
    "        testBin=list(np.random.choice(arr,size=testSize,replace=False,))\n",
    "        trainBin=list(set(arr)-set(testBin))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(testBin)\n",
    "            np.random.shuffle(trainBin)\n",
    "        folds.append({\"train\":trainBin,\"test\":testBin})\n",
    "\n",
    "    return folds\n",
    "\n",
    "def gen_kFold_TrainTestSplit(arr,k,trP,fileName=\"kFoldGen.sav\"):\n",
    "    folds=kFold_TrainTestSplit(arr,k,trP)\n",
    "    joblib.dump(folds,fileName)\n",
    "\n",
    "def load_kFold_TrainTestSplit(fileName=\"kFoldGen.sav\"):\n",
    "    \"\"\"\n",
    "    returns a list of size k:\n",
    "    [{\"train\":[tr_k],\"test\":[te_k]},...]\n",
    "    \"\"\"\n",
    "    \n",
    "    return joblib.load(fileName)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "transforms_dic = {\n",
    "    'train': Compose([\n",
    "        RandRotate(range_x=rand_rot_rad, \n",
    "                    range_y=rand_rot_rad, \n",
    "                    range_z=rand_rot_rad, \n",
    "                    prob=aug_prob),\n",
    "        RandGaussianNoise(std=rand_noise_std, prob=aug_prob),\n",
    "        Affine(translate_params=(rand_shift,\n",
    "                                    rand_shift,\n",
    "                                    rand_shift), \n",
    "                image_only=True),\n",
    "        RandZoom(min_zoom=min_zoom, max_zoom=max_zoom, prob=aug_prob),\n",
    "        RepeatChannel(repeats=channels),\n",
    "    ]),\n",
    "    'train_noaug': None,\n",
    "    'project_noaug':None,\n",
    "    'val': None,\n",
    "    'test': None,\n",
    "    'test_projection': None,\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "transforms_dic = {\n",
    "    'train': Compose([\n",
    "        RandRotate(range_x=rand_rot_rad, \n",
    "                    range_y=rand_rot_rad, \n",
    "                    range_z=rand_rot_rad, \n",
    "                    prob=aug_prob),\n",
    "        RandGaussianNoise(std=rand_noise_std, prob=aug_prob),\n",
    "        Affine(translate_params=(rand_shift,\n",
    "                                    rand_shift,\n",
    "                                    rand_shift), \n",
    "                image_only=True),\n",
    "        RandZoom(min_zoom=min_zoom, max_zoom=max_zoom, prob=aug_prob),\n",
    "        RepeatChannel(repeats=channels),\n",
    "    ]),\n",
    "    'train_noaug': Compose([RepeatChannel(repeats=channels)]),\n",
    "    'project_noaug':Compose([RepeatChannel(repeats=channels)]),\n",
    "    'val': Compose([RepeatChannel(repeats=channels)]),\n",
    "    'test': Compose([RepeatChannel(repeats=channels)]),\n",
    "    'test_projection': Compose([RepeatChannel(repeats=channels)]),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class AugSupervisedDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset_h5path,\n",
    "                 yflag_dict,\n",
    "                 subsetKeys=None,\n",
    "                 transform = None,\n",
    "\n",
    "                 ):\n",
    "        self.dataset_path=dataset_h5path\n",
    "\n",
    "        self.yflag_dict=yflag_dict\n",
    "        if subsetKeys:\n",
    "            self.subsetKeys=subsetKeys\n",
    "        else:\n",
    "            with h5py.File(self.dataset_path, 'r') as f:\n",
    "                self.subsetKeys=list(f.keys())\n",
    "                self.subsetKeys.sort()\n",
    "        \n",
    "        #if transform is None:\n",
    "        #    self.transform = lambda x: x\n",
    "        #else:\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        if hasattr(self.subsetKeys, '__len__'):\n",
    "            return len(self.subsetKeys)\n",
    "        elif self.subsetKeys is None:\n",
    "            length=0\n",
    "            with h5py.File(self.dataset_path, 'r') as f:\n",
    "                length=len(f.keys)\n",
    "            return length\n",
    "        \n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        id=self.subsetKeys[idx]\n",
    "        label=self.yflag_dict[f\"Breast_MRI_{str(id).zfill(3)}\"]\n",
    "        with h5py.File(self.dataset_path, 'r') as f:\n",
    "            image=f[str(id)]['data'][:]\n",
    "        \n",
    "        volume = torch.tensor(image) # torch.Size([160, 229, 193])\n",
    "        #volume = torch.unsqueeze(volume, 0) # add channel dimension\n",
    "        #volume = volume.float()\n",
    "        \n",
    "        if self.transform:\n",
    "            volume = self.transform(volume)\n",
    "            img_min = volume.min()\n",
    "            img_max = volume.max()\n",
    "            volume = (volume-img_min)/(img_max-img_min)\n",
    "\n",
    "        return volume, label\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "class TwoAugSelfSupervisedDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset_h5path,\n",
    "                 yflag_dict,\n",
    "                 subsetKeys=None,\n",
    "                 transform = None,\n",
    "\n",
    "                 ):\n",
    "        self.dataset_path=dataset_h5path\n",
    "\n",
    "        self.yflag_dict=yflag_dict\n",
    "        if subsetKeys:\n",
    "            self.subsetKeys=subsetKeys\n",
    "        else:\n",
    "            with h5py.File(self.dataset_path, 'r') as f:\n",
    "                self.subsetKeys=list(f.keys())\n",
    "                self.subsetKeys.sort()\n",
    "        \n",
    "        #if transform is None:\n",
    "        #    self.transform = lambda x: x\n",
    "        #else:\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        if hasattr(self.subsetKeys, '__len__'):\n",
    "            return len(self.subsetKeys)\n",
    "        elif self.subsetKeys is None:\n",
    "            length=0\n",
    "            with h5py.File(self.dataset_path, 'r') as f:\n",
    "                length=len(f.keys)\n",
    "            return length\n",
    "        \n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        id=self.subsetKeys[idx]\n",
    "        label=self.yflag_dict[f\"Breast_MRI_{str(id).zfill(3)}\"]\n",
    "        with h5py.File(self.dataset_path, 'r') as f:\n",
    "            image=f[str(id)]['data'][:]\n",
    "        \n",
    "        volume = torch.tensor(image) # torch.Size([160, 229, 193])\n",
    "        #volume = torch.unsqueeze(volume, 0) # add channel dimension\n",
    "        #volume = volume.float()\n",
    "        volumes=[]\n",
    "\n",
    "        if self.transform:\n",
    "            for i in range(2):\n",
    "                newVolume = self.transform(volume)\n",
    "                img_min = newVolume.min()\n",
    "                img_max = newVolume.max()\n",
    "                newVolume  = (newVolume -img_min)/(img_max-img_min)\n",
    "                volumes.append(newVolume)\n",
    "        else:\n",
    "            volumes=[volume,volume]\n",
    "            \n",
    "\n",
    "        return volumes[0],volumes[1], label\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def construct_data(\n",
    "        dataset_h5path,\n",
    "        yflag_df,\n",
    "        yLabelColumn='StagingNodes',\n",
    "        k_fold = 5,\n",
    "        test_p=.2,\n",
    "        val_p=.05,\n",
    "        seed=42,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    k-fold and returns dataset classes for \n",
    "    trainset, trainset_pretraining, trainset_normal, trainset_normal_augment, projectset, valset, testset, testset_projection \n",
    "    \"\"\"\n",
    "    patientNums=[int(i.split(\"_\")[-1]) for i in yflag_df.index] #following Breast_MRI_\"i\".zfill(3) convention\n",
    "    validPatients=[i for i in patientNums if not np.isnan(yflag_df[yLabelColumn][f\"Breast_MRI_{str(i).zfill(3)}\"])]\n",
    "    with h5py.File(dataset_h5path, 'r') as f:\n",
    "        validPatients=[i for i in validPatients if str(i) in f.keys()]\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #not using below right.. implementation of 1 of k folds.\n",
    "\n",
    "    trainTestFolds=kFold_TrainTestSplit(validPatients,k=k_fold,testP=test_p)[0]\n",
    "    trainValFolds=kFold_TrainTestSplit(trainTestFolds['train'],k=k_fold,testP=val_p/(1-test_p))[0]\n",
    "    trainValFolds={'train':trainValFolds['train'],'val':trainValFolds['test']}\n",
    "    trainTestFolds.update(trainValFolds)\n",
    "\n",
    "    folds=trainTestFolds # keys 'train' 'test' 'val'\n",
    "    #\n",
    "    # modify yflag_dict expression here if you want to modify the way we define classification\n",
    "    yflag_dict={ind:yflag_df[yLabelColumn][ind]>=1 for ind in yflag_df.index}\n",
    "\n",
    "    trainset = TwoAugSelfSupervisedDataset(\n",
    "        dataset_h5path,\n",
    "                 yflag_dict,\n",
    "                 subsetKeys=folds['train'],\n",
    "                 transform = transforms_dic['train'],\n",
    "        )\n",
    "    trainset_pretraining = TwoAugSelfSupervisedDataset(\n",
    "        dataset_h5path,\n",
    "                 yflag_dict,\n",
    "                 subsetKeys=folds['train'],\n",
    "                 transform = transforms_dic['train'],\n",
    "        )\n",
    "    trainset_normal = AugSupervisedDataset(\n",
    "        dataset_h5path,\n",
    "                 yflag_dict,\n",
    "                 subsetKeys=folds['train'],\n",
    "                 transform = transforms_dic['train_noaug'],\n",
    "        )\n",
    "    trainset_normal_augment = AugSupervisedDataset(\n",
    "        dataset_h5path,\n",
    "                 yflag_dict,\n",
    "                 subsetKeys=folds['train'],\n",
    "                 transform = transforms_dic['train'],\n",
    "        )\n",
    "    projectset = AugSupervisedDataset(\n",
    "        dataset_h5path,\n",
    "                 yflag_dict,\n",
    "                 subsetKeys=folds['train'],\n",
    "                 transform = transforms_dic['project_noaug'],\n",
    "        )\n",
    "    valset = AugSupervisedDataset(\n",
    "        dataset_h5path,\n",
    "                 yflag_dict,\n",
    "                 subsetKeys=folds['val'],\n",
    "                 transform = transforms_dic['val'],\n",
    "        )\n",
    "    testset = AugSupervisedDataset(\n",
    "        dataset_h5path,\n",
    "                 yflag_dict,\n",
    "                 subsetKeys=folds['test'],\n",
    "                 transform = transforms_dic['test'],\n",
    "        )\n",
    "    testset_projection = AugSupervisedDataset(\n",
    "        dataset_h5path,\n",
    "                 yflag_dict,\n",
    "                 subsetKeys=folds['test'],\n",
    "                 transform = transforms_dic['test_projection'],\n",
    "        )\n",
    "    return trainset, trainset_pretraining, trainset_normal, trainset_normal_augment, projectset, valset, testset, testset_projection \n",
    "\n",
    "\n",
    "\n",
    "def get_dataloaders(dataset_h5path,\n",
    "        yflag_df,\n",
    "        yLabelColumn='StagingNodes',\n",
    "        k_fold = 5,\n",
    "        test_p=.2,\n",
    "        val_p=.05,\n",
    "        batchSize=25,\n",
    "        num_workers=1,\n",
    "        seed=42,):\n",
    "    \"\"\"\n",
    "    calls get_data and returns DataLoaders\n",
    "    \"\"\"\n",
    "    trainset, trainset_pretraining, trainset_normal, trainset_normal_augment, projectset, valset, testset, testset_projection = construct_data(dataset_h5path,\n",
    "        yflag_df,\n",
    "        yLabelColumn=yLabelColumn,\n",
    "        k_fold = k_fold,\n",
    "        test_p=test_p,\n",
    "        val_p=val_p,\n",
    "        seed=seed,)\n",
    "    \n",
    "    usePins= useGPU and torch.cuda.is_available()\n",
    "    to_shuffle = True\n",
    "    sampler = None\n",
    "\n",
    "\n",
    "    pretrain_batchsize = batchSize\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        dataset = trainset,\n",
    "        batch_size = batchSize,\n",
    "        shuffle = to_shuffle,\n",
    "        sampler = sampler,\n",
    "        pin_memory = usePins,\n",
    "        num_workers = num_workers,\n",
    "        worker_init_fn = np.random.seed(seed),\n",
    "        drop_last = True)\n",
    "           \n",
    "    trainloader_pretraining = torch.utils.data.DataLoader(\n",
    "        dataset = trainset_pretraining,\n",
    "        batch_size = pretrain_batchsize,\n",
    "        shuffle = to_shuffle,\n",
    "        sampler = sampler,\n",
    "        pin_memory = usePins,\n",
    "        num_workers = num_workers,\n",
    "        worker_init_fn = np.random.seed(seed),\n",
    "        drop_last = True)\n",
    "    \n",
    "    trainloader_normal = torch.utils.data.DataLoader(\n",
    "        dataset = trainset_normal,\n",
    "        batch_size = batchSize,\n",
    "        shuffle = False, \n",
    "        sampler = sampler,\n",
    "        pin_memory = usePins,\n",
    "        num_workers = num_workers,\n",
    "        worker_init_fn = np.random.seed(seed),\n",
    "        drop_last = True)\n",
    "        \n",
    "    trainloader_normal_augment = torch.utils.data.DataLoader(\n",
    "        dataset = trainset_normal_augment,\n",
    "        batch_size = batchSize,\n",
    "        shuffle = to_shuffle,\n",
    "        sampler = sampler,\n",
    "        pin_memory = usePins,\n",
    "        num_workers = num_workers,\n",
    "        worker_init_fn = np.random.seed(seed),\n",
    "        drop_last = True)\n",
    "    \n",
    "    projectloader = torch.utils.data.DataLoader(\n",
    "        dataset = projectset,\n",
    "        batch_size = 1,\n",
    "        shuffle = False, \n",
    "        sampler = sampler,\n",
    "        pin_memory = usePins,\n",
    "        num_workers = num_workers,\n",
    "        worker_init_fn = np.random.seed(seed),\n",
    "        drop_last = True)\n",
    "    \n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        dataset = valset,\n",
    "        batch_size = 1,\n",
    "        shuffle = True, \n",
    "        pin_memory = usePins,\n",
    "        num_workers = num_workers,                \n",
    "        worker_init_fn = np.random.seed(seed),\n",
    "        drop_last = False)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        dataset = testset,\n",
    "        batch_size = 1,\n",
    "        shuffle = False, \n",
    "        pin_memory = usePins,\n",
    "        num_workers = num_workers,                \n",
    "        worker_init_fn = np.random.seed(seed),\n",
    "        drop_last = False)\n",
    "    \n",
    "    test_projectloader = torch.utils.data.DataLoader(\n",
    "        dataset = testset_projection,\n",
    "        batch_size = 1,\n",
    "        shuffle = False, \n",
    "        pin_memory = usePins,\n",
    "        num_workers = num_workers,                \n",
    "        worker_init_fn = np.random.seed(seed),\n",
    "        drop_last = False)\n",
    "\n",
    "    return trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment, projectloader, valloader, testloader, test_projectloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "yflags=pd.read_csv(\"../duke/ClinicalFlags.csv\",index_col=0)\n",
    "\n",
    "\n",
    "dataloaders=get_dataloaders(dataset_h5path='data/firstpass_923_avgCropResize.h5',\n",
    "                            yflag_df=yflags,\n",
    "                            yLabelColumn='StagingNodes',\n",
    "                            k_fold=5,\n",
    "                            test_p=.2,\n",
    "                            val_p=.05,\n",
    "                            batchSize=25,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, trainset_pretraining, trainset_normal, trainset_normal_augment, projectset, valset, testset, testset_projection = construct_data(\n",
    "                            dataset_h5path='data/firstpass_923_avgCropResize.h5',\n",
    "                            yflag_df=yflags,\n",
    "                            yLabelColumn='StagingNodes',\n",
    "                            k_fold=5,\n",
    "                            test_p=.2,\n",
    "                            val_p=.05,\n",
    "                            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.spatial.array.RandRotate object at 0x000001C0E3464A10>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\transform.py:141\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items, lazy, overrides, log_stats) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _apply_transform(transform, data, unpack_items, lazy, overrides, log_stats)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\transform.py:98\u001b[0m, in \u001b[0;36m_apply_transform\u001b[1;34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transform(data, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(data)\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\spatial\\array.py:1381\u001b[0m, in \u001b[0;36mRandRotate.__call__\u001b[1;34m(self, img, mode, padding_mode, align_corners, dtype, randomize, lazy)\u001b[0m\n\u001b[0;32m   1372\u001b[0m     rotator \u001b[38;5;241m=\u001b[39m Rotate(\n\u001b[0;32m   1373\u001b[0m         angle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz),\n\u001b[0;32m   1374\u001b[0m         keep_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1379\u001b[0m         lazy\u001b[38;5;241m=\u001b[39mlazy_,\n\u001b[0;32m   1380\u001b[0m     )\n\u001b[1;32m-> 1381\u001b[0m     out \u001b[38;5;241m=\u001b[39m rotator(img)\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\spatial\\array.py:956\u001b[0m, in \u001b[0;36mRotate.__call__\u001b[1;34m(self, img, mode, padding_mode, align_corners, dtype, lazy)\u001b[0m\n\u001b[0;32m    955\u001b[0m lazy_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lazy\n\u001b[1;32m--> 956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rotate(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    957\u001b[0m     img,\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mangle,\n\u001b[0;32m    959\u001b[0m     output_shape,\n\u001b[0;32m    960\u001b[0m     _mode,\n\u001b[0;32m    961\u001b[0m     _padding_mode,\n\u001b[0;32m    962\u001b[0m     _align_corners,\n\u001b[0;32m    963\u001b[0m     _dtype,\n\u001b[0;32m    964\u001b[0m     lazy\u001b[38;5;241m=\u001b[39mlazy_,\n\u001b[0;32m    965\u001b[0m     transform_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform_info(),\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\spatial\\functional.py:370\u001b[0m, in \u001b[0;36mrotate\u001b[1;34m(img, angle, output_shape, mode, padding_mode, align_corners, dtype, lazy, transform_info)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ndim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported image dimension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, available options are [2, 3].\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    371\u001b[0m _angle \u001b[38;5;241m=\u001b[39m ensure_tuple_rep(angle, \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Unsupported image dimension: 4, available options are [2, 3].",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainset_normal_augment[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[114], line 121\u001b[0m, in \u001b[0;36mAugSupervisedDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m#volume = volume.float()\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m--> 121\u001b[0m     volume \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(volume)\n\u001b[0;32m    122\u001b[0m     img_min \u001b[38;5;241m=\u001b[39m volume\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m    123\u001b[0m     img_max \u001b[38;5;241m=\u001b[39m volume\u001b[38;5;241m.\u001b[39mmax()\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\compose.py:335\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, input_, start, end, threading, lazy)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, threading\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, lazy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    334\u001b[0m     _lazy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lazy\n\u001b[1;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m execute_compose(\n\u001b[0;32m    336\u001b[0m         input_,\n\u001b[0;32m    337\u001b[0m         transforms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms,\n\u001b[0;32m    338\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[0;32m    339\u001b[0m         end\u001b[38;5;241m=\u001b[39mend,\n\u001b[0;32m    340\u001b[0m         map_items\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_items,\n\u001b[0;32m    341\u001b[0m         unpack_items\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpack_items,\n\u001b[0;32m    342\u001b[0m         lazy\u001b[38;5;241m=\u001b[39m_lazy,\n\u001b[0;32m    343\u001b[0m         overrides\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides,\n\u001b[0;32m    344\u001b[0m         threading\u001b[38;5;241m=\u001b[39mthreading,\n\u001b[0;32m    345\u001b[0m         log_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_stats,\n\u001b[0;32m    346\u001b[0m     )\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\compose.py:111\u001b[0m, in \u001b[0;36mexecute_compose\u001b[1;34m(data, transforms, map_items, unpack_items, start, end, lazy, overrides, threading, log_stats)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threading:\n\u001b[0;32m    110\u001b[0m         _transform \u001b[38;5;241m=\u001b[39m deepcopy(_transform) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_transform, ThreadUnsafe) \u001b[38;5;28;01melse\u001b[39;00m _transform\n\u001b[1;32m--> 111\u001b[0m     data \u001b[38;5;241m=\u001b[39m apply_transform(\n\u001b[0;32m    112\u001b[0m         _transform, data, map_items, unpack_items, lazy\u001b[38;5;241m=\u001b[39mlazy, overrides\u001b[38;5;241m=\u001b[39moverrides, log_stats\u001b[38;5;241m=\u001b[39mlog_stats\n\u001b[0;32m    113\u001b[0m     )\n\u001b[0;32m    114\u001b[0m data \u001b[38;5;241m=\u001b[39m apply_pending_transforms(data, \u001b[38;5;28;01mNone\u001b[39;00m, overrides, logger_name\u001b[38;5;241m=\u001b[39mlog_stats)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\savio\\anaconda3\\Lib\\site-packages\\monai\\transforms\\transform.py:171\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m         _log_stats(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplying transform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransform\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: applying transform <monai.transforms.spatial.array.RandRotate object at 0x000001C0E3464A10>"
     ]
    }
   ],
   "source": [
    "trainset_normal_augment.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=trainset[0][0][0] #([tensors in batch],[labels in batch]) ### according to __getitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=trainset.subsetKeys[2]\n",
    "label = trainset.yflag_dict[f\"Breast_MRI_{str(id).zfill(3)}\"]\n",
    "with h5py.File(trainset.dataset_path, 'r') as f:\n",
    "    image=f[str(id)]['data'][:]\n",
    "volume = torch.tensor(image) # torch.Size([160, 229, 193])\n",
    "#volume = torch.unsqueeze(volume, 0) # add channel dimension\n",
    "if trainset.transform:\n",
    "    volume = trainset.transform(volume)\n",
    "    img_min = volume.min()\n",
    "    img_max = volume.max()\n",
    "    volume = (volume-img_min)/(img_max-img_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph=trainset.transform(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metatensor(0.7750)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader=dataloaders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainDataLoader[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "trainDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume=torch.tensor(patientData[0]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTransform=transforms_dic['train'](volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 142, 512, 512]), torch.Size([1, 162, 488, 488]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.shape,testTransform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yflags['StagingNodes'][\"Breast_MRI_001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
