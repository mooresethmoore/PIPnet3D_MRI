{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from imageio import imread\n",
    "import json\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "current_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "import utils\n",
    "from utils import plot_3d_slices\n",
    "from utils import set_seeds\n",
    "from utils import set_device\n",
    "#from utils import get_optimizer_nn\n",
    "from utils import init_weights_xavier\n",
    "from utils import get_patch_size,generate_rgb_array\n",
    "from utils import Log\n",
    "data_dir = os.path.join(current_dir, 'data')\n",
    "\n",
    "from training_pipnet_LR import get_network,get_optimizer_nn\n",
    "sys.path.append(data_dir)\n",
    "#from make_dataset import get_dataloaders\n",
    "import make_dataset_LR\n",
    "from make_dataset_LR import get_dataloaders,getAllDataloader,getAllDataset\n",
    "# Construct the path to the models directory\n",
    "models_dir = os.path.join(current_dir, 'models')\n",
    "\n",
    "# Add the models directory to sys.path\n",
    "sys.path.append(models_dir)\n",
    "from resnet_features import video_resnet18_features\n",
    "from pipnet import PIPNet,NonNegLinear\n",
    "from train_model_custom import train_pipnet\n",
    "\n",
    "from test_model import eval_pipnet\n",
    "\n",
    "vis_dir=os.path.join(current_dir, 'visualization')\n",
    "sys.path.append(vis_dir)\n",
    "import vis_pipnet\n",
    "#from vis_pipnet import visualize, visualize_topk\n",
    "from vis_pipnet import get_img_coordinates,plot_rgb_slices,plot_local_explanation\n",
    "import plotly.graph_objects as go\n",
    "import xarray as xr\n",
    "import plotly.express as px\n",
    "\n",
    "from scipy.ndimage import binary_erosion\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    RandRotate,\n",
    "    Affine,\n",
    "    RandGaussianNoise,\n",
    "    RandZoom,\n",
    "    RepeatChannel,\n",
    ")\n",
    "import math\n",
    "import joblib\n",
    "import h5py\n",
    "from importlib import reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args={\n",
    "    'log_dir':'logs/OPNorm9995_tan2_backbone1en4_fold1',\n",
    "    'seed':42,\n",
    "    'experiment_folder':'data/experiment_1',\n",
    "    'lr':.0001,\n",
    "    'lr_net':.0001,\n",
    "    'lr_block':.0001,\n",
    "    'lr_class':.0001,\n",
    "    'lr_backbone':.0001,\n",
    "    'weight_decay':0,\n",
    "    'gamma':.1,\n",
    "    'step_size':1,\n",
    "    'batch_size':15,\n",
    "    'epochs':160,\n",
    "    'epochs_pretrain':30,\n",
    "    'freeze_epochs':0,\n",
    "    'epochs_finetune':10,\n",
    "    'num_classes':2,\n",
    "    'channels':3,\n",
    "    'net':\"3Dresnet18\",\n",
    "    'num_features':0,\n",
    "    'bias':False,\n",
    "    'out_shape':1,\n",
    "    'disable_pretrained':False,\n",
    "    'optimizer':'Adam',\n",
    "    'state_dict_dir_net':'',\n",
    "    \"dic_classes\":{False:0,True:1},\n",
    "    'val_split':.05,\n",
    "    'test_split':.2,\n",
    "    'defaultFinetune':True,\n",
    "    'lr_finetune':.05,\n",
    "    'flipTrain':False,\n",
    "    'stratSampling':True,\n",
    "    'excludePatients':['735','322','531','523','876','552'],\n",
    "    'log_power':1,\n",
    "    'img_shape':[54,121,74],\n",
    "    'wshape':5, # this is assigned mid script and doesn't matter here\n",
    "    'hshape':8, # these matter and should bechanged to correct vals for the analyzing_network\n",
    "    'dshape':7,\n",
    "    'backboneStrides':[1,2,2,2],\n",
    "    'patchsize':15\n",
    "}\n",
    "\n",
    "channels=3\n",
    "aug_prob = 1\n",
    "rand_rot = 10                       # random rotation range [deg]\n",
    "rand_rot_rad = rand_rot*math.pi/180 # random rotation range [rad]\n",
    "rand_noise_std = 0.01               # std random Gaussian noise\n",
    "rand_shift = 5                      # px random shift\n",
    "min_zoom = 0.9\n",
    "max_zoom = 1.1\n",
    "transforms_dic = {\n",
    "    'train': Compose([\n",
    "        RandRotate(range_x=rand_rot_rad, \n",
    "                    range_y=rand_rot_rad, \n",
    "                    range_z=rand_rot_rad, \n",
    "                    prob=aug_prob),\n",
    "        RandGaussianNoise(std=rand_noise_std, prob=aug_prob),\n",
    "        Affine(translate_params=(rand_shift,\n",
    "                                    rand_shift,\n",
    "                                    rand_shift), \n",
    "                image_only=True),\n",
    "        RandZoom(min_zoom=min_zoom, max_zoom=max_zoom, prob=aug_prob),\n",
    "        RepeatChannel(repeats=channels),\n",
    "    ]),\n",
    "    'train_noaug': Compose([RepeatChannel(repeats=channels)]),\n",
    "    'project_noaug':Compose([RepeatChannel(repeats=channels)]),\n",
    "    'val': Compose([RepeatChannel(repeats=channels)]),\n",
    "    'test': Compose([RepeatChannel(repeats=channels)]),\n",
    "    'test_projection': Compose([RepeatChannel(repeats=channels)]),\n",
    "}\n",
    "\n",
    "downSample=3.2\n",
    "lowerBound=.15\n",
    "#inputData=f'data/FP923_LR_avgCrop_DS{int(downSample*10)}_point{int(lowerBound*100)}Thresh.h5'\n",
    "inputData=f'data/FP_LR_OPNorm_avgcrop_DS{int(downSample*10)}_point{int(lowerBound*100)}Thresh.h5'\n",
    "#inputData=f'data/syntheticData_balls_LR_fixed.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useGPU=True\n",
    "devID=0\n",
    "if useGPU:\n",
    "    device=torch.device(f'cuda:{devID}')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "#yflags=pd.read_csv(\"../duke/ClinicalFlags.csv\",index_col=0)\n",
    "\n",
    "\n",
    "dataloaders=get_dataloaders(dataset_h5path=inputData,\n",
    "                            k_fold=5,\n",
    "                            test_p=.2,\n",
    "                            val_p=.05,\n",
    "                            batchSize=args['batch_size'],\n",
    "                            seed=args['seed'],\n",
    "                            kMeansSaveDir=\"data/kMeans_DS32.json\")\n",
    "\n",
    "trainloader = dataloaders[0]\n",
    "trainloader_pretraining = dataloaders[1]\n",
    "trainloader_normal = dataloaders[2] \n",
    "trainloader_normal_augment = dataloaders[3]\n",
    "projectloader = dataloaders[4]\n",
    "valloader = dataloaders[5]\n",
    "testloader = dataloaders[6] \n",
    "test_projectloader = dataloaders[7]\n",
    "\n",
    "allData=getAllDataset(inputData)\n",
    "inputKeys=allData.subsetKeys\n",
    "\n",
    "\n",
    "network_layers = get_network(num_classes=args['num_classes'], args=args)\n",
    "feature_net = network_layers[0]\n",
    "add_on_layers = network_layers[1]\n",
    "pool_layer = network_layers[2]\n",
    "classification_layer = network_layers[3]\n",
    "num_prototypes = network_layers[4]\n",
    "newFeatures=feature_net\n",
    "net = PIPNet(\n",
    "        num_classes = args['num_classes'],\n",
    "        num_prototypes = num_prototypes,\n",
    "        feature_net = newFeatures,\n",
    "        args = args,\n",
    "        add_on_layers = add_on_layers,\n",
    "        pool_layer = pool_layer,\n",
    "        classification_layer = classification_layer\n",
    "        )\n",
    "net = net.to(device=device)\n",
    "net = nn.DataParallel(net, device_ids = [0])  \n",
    "\n",
    "\n",
    "optimizer = get_optimizer_nn(net, args)\n",
    "optimizer_net = optimizer[0]\n",
    "optimizer_classifier = optimizer[1] \n",
    "params_to_freeze = optimizer[2] \n",
    "params_to_train = optimizer[3] \n",
    "params_backbone = optimizer[4]   \n",
    "\n",
    "checkpointFile=f\"{args['log_dir']}/checkpoints/net_trained_last\"\n",
    "checkpoint = torch.load(checkpointFile, map_location = device)\n",
    "net.load_state_dict(checkpoint['model_state_dict'], strict = True) \n",
    "net.module._multiplier.requires_grad = False\n",
    "try:\n",
    "    optimizer_net.load_state_dict(\n",
    "        checkpoint['optimizer_net_state_dict']) \n",
    "except:\n",
    "    print(\"optimizer failed load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliceViewer(images,labels, key: str, title: str, height:int):\n",
    "    if len(images.shape)==3:\n",
    "        newIm=RepeatChannel(3)(images.unsqueeze(0))\n",
    "        newIm=torch.moveaxis(newIm,[0,1,2,3],[-1,0,1,2])\n",
    "    else:\n",
    "        newIm=images\n",
    "    xrData = xr.DataArray(\n",
    "        data   = newIm,\n",
    "        dims   = [key, 'row', 'col', 'rgb'],\n",
    "        coords = {key: labels}\n",
    "    )\n",
    "    # Hide the axes\n",
    "    #layout_dict = dict(yaxis_visible=False, yaxis_showticklabels=False, xaxis_visible=False, xaxis_showticklabels=False)\n",
    "    layout_dict=dict()\n",
    "    return px.imshow(xrData, title=title, animation_frame=key).update_layout(layout_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleSliceViewer(images, labels1, labels2, key1: str, key2: str, title: str, height: int):\n",
    "    if len(images.shape) != 5 or images.shape[-1] != 3:\n",
    "        raise ValueError(\"Input images must be a 5D tensor (N, M, H, W, 3) where the last dimension represents RGB channels.\")\n",
    "\n",
    "    # Convert to numpy if necessary\n",
    "    if isinstance(images, torch.Tensor):\n",
    "        images = images.numpy()\n",
    "\n",
    "    # Ensure the image data is in the [0, 255] range for display\n",
    "    if images.max() <= 1.0:\n",
    "        images = (images * 255).astype(np.uint8)\n",
    "\n",
    "    # Initial image from the first slice in both dimensions\n",
    "    initial_image = images[0, 0]\n",
    "\n",
    "    # Create the figure and add the initial image\n",
    "    fig = go.Figure(data=go.Image(z=initial_image))\n",
    "\n",
    "    # Prepare the frames\n",
    "    frames = []\n",
    "    for i in range(images.shape[0]):\n",
    "        for j in range(images.shape[1]):\n",
    "            frames.append(go.Frame(\n",
    "                data=go.Image(z=images[i, j]),\n",
    "                name=f'{i}-{j}'\n",
    "            ))\n",
    "\n",
    "    fig.frames = frames\n",
    "\n",
    "    # Define the sliders\n",
    "    slider1 = {\n",
    "        \"active\": 0,\n",
    "        \"currentvalue\": {\"prefix\": f\"{key1}: \"},\n",
    "        \"pad\": {\"t\": 100},\n",
    "        \"steps\": [],\n",
    "        \"y\":0.20\n",
    "    }\n",
    "\n",
    "    slider2 = {\n",
    "        \"active\": 0,\n",
    "        \"currentvalue\": {\"prefix\": f\"{key2}: \"},\n",
    "        \"pad\": {\"t\": 150},\n",
    "        \"steps\": [],\n",
    "        \"y\":0\n",
    "    }\n",
    "\n",
    "    # Update layout with sliders\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        sliders=[slider1, slider2],\n",
    "        height=height,\n",
    "        margin=dict(t=80, b=250, l=40, r=40)\n",
    "    )\n",
    "\n",
    "    # Add steps to sliders dynamically\n",
    "    fig.layout.sliders[0].steps = [\n",
    "        {\n",
    "            \"args\": [\n",
    "                [f\"{i}-{fig.layout.sliders[1].active}\"],  # Reference to second slider's active value\n",
    "                {\"frame\": {\"duration\": 0, \"redraw\": True}, \"mode\": \"immediate\"}\n",
    "            ],\n",
    "            \"label\": str(label1),\n",
    "            \"method\": \"animate\",\n",
    "        }\n",
    "        for i, label1 in enumerate(labels1)\n",
    "    ]\n",
    "\n",
    "    fig.layout.sliders[1].steps = [\n",
    "        {\n",
    "            \"args\": [\n",
    "                [f\"{fig.layout.sliders[0].active}-{j}\"],  # Reference to first slider's active value\n",
    "                {\"frame\": {\"duration\": 0, \"redraw\": True}, \"mode\": \"immediate\"}\n",
    "            ],\n",
    "            \"label\": str(label2),\n",
    "            \"method\": \"animate\",\n",
    "        }\n",
    "        for j, label2 in enumerate(labels2)\n",
    "    ]\n",
    "\n",
    "    return fig\n",
    "\n",
    "def generate_unique_colormap(size, colormap_name='viridis'):\n",
    "    \"\"\"\n",
    "    Generates a unique colormap of a given size.\n",
    "\n",
    "    :param size: Number of unique colors needed.\n",
    "    :param colormap_name: Name of the matplotlib colormap to use (default is 'viridis').\n",
    "    :return: A list of RGBA color tuples.\n",
    "    \"\"\"\n",
    "    cmap = plt.get_cmap(colormap_name, size)  # Create a colormap with `size` unique colors\n",
    "    return cmap(np.arange(size))  # Generate the colormap array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes=[]\n",
    "for i in range(5):\n",
    "    arr,label=allData[inputKeys[i]]\n",
    "    args['img_shape']=list(arr.shape[1:])\n",
    "    arr=RepeatChannel(repeats=3)(arr)\n",
    "    arr.shape\n",
    "\n",
    "\n",
    "    volume=arr\n",
    "    volumeRGB=np.moveaxis(volume,[0,1,2,3],[-1,0,1,2])\n",
    "    volumes.append(volumeRGB)\n",
    "\n",
    "volumes=torch.tensor(np.array(volumes))\n",
    "depthLen=volumes.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = list(range(5))  # Labels for the first slider\n",
    "labels2 = list(range(depthLen))   # Labels for the second slider\n",
    "fig = doubleSliceViewer(volumes, labels1, labels2, 'slider1', 'slider2', 'Slice Viewer', 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_patchResize(key=\"20_R\",thresh=.5,greyscaleGrad=True):\n",
    "    classification_weights = net.module._classification.weight#.detach().cpu()\n",
    "    relevantWeights=torch.gt(\n",
    "        net.module._classification.weight, 1e-3).any(dim = 0) #used in eval_pipnet to count relevantProtos for excel\n",
    "    topKProtos=torch.nonzero(relevantWeights).detach().cpu()\n",
    "\n",
    "    arr,label=projectloader.dataset[key]\n",
    "    transform=Compose([Resize(spatial_size=arr.shape[1:],mode=\"nearest\")])\n",
    "    print(f\"resizeShape {arr.shape[1:]}\")\n",
    "    xs=arr.unsqueeze(0).to(device)\n",
    "    xs.requires_grad=True\n",
    "    features = net.module._net(xs)\n",
    "    proto_features = net.module._add_on(features) #does any form of gradient accrue on features here?\n",
    "    proto_features=proto_features.detach().cpu()\n",
    "    protoThresh=proto_features > thresh\n",
    "    topKProtos={int(k) for k in topKProtos if torch.any(protoThresh[0][k])}\n",
    "    image_information={\n",
    "        k:{\"gradient\":torch.zeros_like(arr),\n",
    "           \"patch\":torch.zeros_like(arr), \n",
    "            \"simweightTrue\":-1,\n",
    "            \"simweightPred\":-1,\n",
    "           }\n",
    "        for k in topKProtos\n",
    "    }\n",
    "    print(f\"topKProtos : {topKProtos}\")\n",
    "    for proto in topKProtos:\n",
    "        patchResize=transform(protoThresh[0][proto].unsqueeze(0))[0].detach().cpu().numpy()\n",
    "\n",
    "        erosion_mask=binary_erosion(patchResize)\n",
    "        #patches[proto]=patchResize-erosion_mask\n",
    "        image_information[proto]['patch']=patchResize-erosion_mask\n",
    "        releventIndices=[(i,j,k) for i in range(features.shape[2]) for j in range(features.shape[3]) for k in range(features.shape[4]) if protoThresh[0][proto][i][j][k]==1]\n",
    "        if len(releventIndices)>0:\n",
    "            \n",
    "            i,j,k=releventIndices[0]\n",
    "            ijkVec=torch.tensor([features[0][p][i][j][k] for p in topKProtos if p!=proto])\n",
    "\n",
    "            #gradient=torch.autograd.grad(features[0][proto][i][j][k],xs,retain_graph=True)[0]\n",
    "            gradient=torch.autograd.grad(features[0][proto][i][j][k]-torch.log(torch.sum(torch.exp(ijkVec))),xs,retain_graph=True)[0]\n",
    "            \n",
    "            for i,j,k in releventIndices[1:]:\n",
    "\n",
    "                #gradient+=torch.autograd.grad(features[0][proto][i][j][k],xs,retain_graph=True)[0]\n",
    "                ijkVec=torch.tensor([features[0][p][i][j][k] for p in topKProtos if p!=proto])\n",
    "                gradient+=torch.autograd.grad(features[0][proto][i][j][k]-torch.log(torch.sum(torch.exp(ijkVec))),xs,retain_graph=True)[0]\n",
    "            gradient=gradient[0].detach().cpu().numpy()\n",
    "            #absolute val + normalization\n",
    "            gradient=np.abs(gradient)\n",
    "            if gradient.max()>gradient.min():\n",
    "                gradient=(gradient-gradient.min())/(gradient.max()-gradient.min())\n",
    "            #print(f\"gradientshape {gradient.shape}\")\n",
    "            if greyscaleGrad:\n",
    "                gradient=np.array([gradient.mean(axis=0) for c in range(3)])\n",
    "            image_information[proto]['gradient']=gradient\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        ### idk if I can do this earlier since operations are being performed on grad features? \n",
    "\n",
    "        proto_features, clamped_pooled, out = net(xs)\n",
    "        proto_features=proto_features.detach().cpu()\n",
    "        clamped_pooled=clamped_pooled.detach().cpu()\n",
    "        out = out.detach().cpu()\n",
    "\n",
    "        for proto in topKProtos:\n",
    "            \n",
    "            image_information[proto]['simweightTrue']=clamped_pooled[0][int(proto)]*classification_weights[int(label),int(proto)]\n",
    "            image_information[proto]['simweightPred']=clamped_pooled[0][int(proto)]*classification_weights[np.argmax(out[0].numpy()),int(proto)]\n",
    "\n",
    "    return image_information,label,out\n",
    "\n",
    "\n",
    "def plot_gradient_patchResize(key=42,thresh=.5,greyscaleGrad=True,overlayOriginal=False,title=\"grad explanation\",height=1200,returnImageInfo=True, proto_colormap_name='viridis'):    \n",
    "    image_information,label,out=gradient_patchResize(key=key,thresh=thresh,greyscaleGrad=greyscaleGrad)\n",
    "    #sort by either simweightTrue or simweightPred\n",
    "    proto_information_sorted=[(k,v) for k,v in image_information.items()]\n",
    "    proto_information_sorted.sort(key=lambda x: x[1]['simweightPred'],reverse=True)\n",
    "\n",
    "    #protoVolumesRGB=np.array([i[1]['gradient'].copy() for i in proto_information_sorted])\n",
    "    protoVolumesRGB=np.array([np.moveaxis(i[1]['gradient'],[0,1,2,3],[-1,0,1,2]) for i in proto_information_sorted])\n",
    "    #shape is (k,d,r,c,3)\n",
    "    cmap=generate_unique_colormap(size=len(proto_information_sorted),colormap_name=proto_colormap_name) #color by proto\n",
    "    \n",
    "    for i,(k,v) in enumerate(proto_information_sorted):\n",
    "        for c in range(3):\n",
    "            protoVolumesRGB[i,:,:,:,c]+=v['patch']*cmap[i][c]\n",
    "    if overlayOriginal:\n",
    "        arr,label=projectloader.dataset[key]\n",
    "        protoVolumesRGB+=np.array([np.moveaxis(arr,[0,1,2,3],[-1,0,1,2]) for i in range(len(protoVolumesRGB))])\n",
    "    for k in range(len(protoVolumesRGB)):\n",
    "        maximum,minimum=protoVolumesRGB[k].max(),protoVolumesRGB[k].min()\n",
    "        if maximum>minimum:\n",
    "            protoVolumesRGB[k]=(protoVolumesRGB[k]-minimum)/(maximum-minimum)\n",
    "    labels1 = list(k for k,v in proto_information_sorted)  # Labels for the first slider\n",
    "    labels2 = list(range(proto_information_sorted[0][1]['patch'].shape[0]))   # Labels for the second slider\n",
    "    fig = doubleSliceViewer(protoVolumesRGB, labels1, labels2, 'Proto', 'MRI depth', title, height)\n",
    "\n",
    "    return fig,image_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,image_information=plot_gradient_patchResize(key=\"20_R\",thresh=.5,greyscaleGrad=False,overlayOriginal=True,title=\"grad explanation\",height=800,returnImageInfo=True, proto_colormap_name='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=42;thresh=.5;greyscaleGrad=True;overlayOriginal=False;title=\"grad explanation\";height=1200;returnImageInfo=True; proto_colormap_name='viridis'\n",
    "image_information,label,out=gradient_patchResize(key=key,thresh=thresh,greyscaleGrad=greyscaleGrad)\n",
    "#sort by either simweightTrue or simweightPred\n",
    "proto_information_sorted=[(k,v) for k,v in image_information.items()]\n",
    "proto_information_sorted.sort(key=lambda x: x[1]['simweightPred'],reverse=True)\n",
    "\n",
    "#protoVolumesRGB=np.array([i[1]['gradient'].copy() for i in proto_information_sorted])\n",
    "protoVolumesRGB=np.array([np.moveaxis(i[1]['gradient'],[0,1,2,3],[-1,0,1,2]) for i in proto_information_sorted])\n",
    "#shape is (k,d,r,c,3)\n",
    "cmap=generate_unique_colormap(size=len(proto_information_sorted),colormap_name=proto_colormap_name) #color by proto\n",
    "\n",
    "for i,(k,v) in enumerate(proto_information_sorted):\n",
    "    for c in range(3):\n",
    "        protoVolumesRGB[i,:,:,:,c]+=v['patch']*cmap[i][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr,label=projectloader.dataset[key]\n",
    "\n",
    "volume=arr\n",
    "volumeRGB=np.moveaxis(volume,[0,1,2,3],[-1,0,1,2])\n",
    "\n",
    "sliceViewer(volumeRGB,[i for i in range(len(volumeRGB))],key=\"Depth\",title=\"test\",height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
